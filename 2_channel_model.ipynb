{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple leaf', 'Apple rust leaf', 'Apple Scab Leaf', 'Bell_pepper leaf', 'Bell_pepper leaf spot', 'Blueberry leaf', 'Cherry leaf', 'Corn Gray leaf spot', 'Corn leaf blight', 'Corn rust leaf', 'grape leaf', 'grape leaf black rot', 'Peach leaf', 'Potato leaf early blight', 'Potato leaf late blight', 'Raspberry leaf', 'Soyabean leaf', 'Squash Powdery mildew leaf', 'Strawberry leaf', 'Tomato Early blight leaf', 'Tomato leaf', 'Tomato leaf bacterial spot', 'Tomato leaf late blight', 'Tomato leaf mosaic virus', 'Tomato leaf yellow virus', 'Tomato mold leaf', 'Tomato Septoria leaf spot', 'Tomato two spotted spider mites leaf']\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir('E:\\\\Plant Doc Disease Classification\\\\PlantDoc-Dataset-master\\\\train')\n",
    "tclasses = os.listdir('E:\\\\Plant Doc Disease Classification\\\\PlantDoc-Dataset-master\\\\test')\n",
    "print(tclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1960 images belonging to 28 classes.\n",
      "Found 227 images belonging to 28 classes.\n",
      "Found 1960 images belonging to 28 classes.\n",
      "Found 227 images belonging to 28 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "gray_train_datagen = datagen.flow_from_directory('E:\\\\Plant Doc Disease Classification\\\\PlantDoc-Dataset-master\\\\gray_train',\n",
    "                                            target_size = (128,128),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode = 'categorical')\n",
    "gray_test_datagen = datagen.flow_from_directory('E:\\\\Plant Doc Disease Classification\\\\PlantDoc-Dataset-master\\\\gray_test',\n",
    "                                            target_size = (128,128),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode = 'categorical')\n",
    "train_datagen = datagen.flow_from_directory('E:\\\\Plant Doc Disease Classification\\\\PlantDoc-Dataset-master\\\\train',\n",
    "                                            target_size = (128,128),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode = 'categorical')\n",
    "test_datagen = datagen.flow_from_directory('E:\\\\Plant Doc Disease Classification\\\\PlantDoc-Dataset-master\\\\test',\n",
    "                                            target_size = (128,128),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 126, 126, 32  896         ['input_11[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 126, 126, 32  896         ['input_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_20 (AverageP  (None, 63, 63, 32)  0           ['conv2d_20[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling2d_22 (AverageP  (None, 63, 63, 32)  0           ['conv2d_22[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 61, 61, 64)   18496       ['average_pooling2d_20[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 61, 61, 64)   18496       ['average_pooling2d_22[0][0]']   \n",
      "                                                                                                  \n",
      " average_pooling2d_21 (AverageP  (None, 30, 30, 64)  0           ['conv2d_21[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling2d_23 (AverageP  (None, 30, 30, 64)  0           ['conv2d_23[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 57600)        0           ['average_pooling2d_21[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)           (None, 57600)        0           ['average_pooling2d_23[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 115200)       0           ['flatten_10[0][0]',             \n",
      "                                                                  'flatten_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          14745728    ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 28)           3612        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,788,124\n",
      "Trainable params: 14,788,124\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rgb = tf.keras.layers.Input(shape=(128,128,3))\n",
    "lab = tf.keras.layers.Input(shape=(128,128,3))\n",
    "\n",
    "model1 = tf.keras.layers.Conv2D(32,kernel_size= (3,3), strides= (1,1), activation = 'relu')(rgb)\n",
    "model1 = tf.keras.layers.AveragePooling2D((2,2))(model1)\n",
    "model1 = tf.keras.layers.Conv2D(64,kernel_size= (3,3), strides= (1,1), activation = 'relu')(model1)\n",
    "model1 = tf.keras.layers.AveragePooling2D((2,2))(model1)\n",
    "out1 = tf.keras.layers.Flatten()(model1)\n",
    "#model1 = tf.keras.Model(inputs = rgb, outputs = model1)\n",
    "\n",
    "model2 = tf.keras.layers.Conv2D(32,kernel_size= (3,3), strides= (1,1), activation = 'relu')(lab)\n",
    "model2 = tf.keras.layers.AveragePooling2D((2,2))(model2)\n",
    "model2 = tf.keras.layers.Conv2D(64,kernel_size= (3,3), strides= (1,1), activation = 'relu')(model2)\n",
    "model2 = tf.keras.layers.AveragePooling2D((2,2))(model2)\n",
    "out2 = tf.keras.layers.Flatten()(model2)\n",
    "#model2 = tf.keras.Model(inputs = lab, outputs = model2)\n",
    "\n",
    "conc = tf.keras.layers.Concatenate()([out1, out2])\n",
    "\n",
    "final = tf.keras.layers.Dense(128, activation= 'relu')(conc)\n",
    "final = tf.keras.layers.Dense(len(classes), activation= 'softmax')(final)\n",
    "\n",
    "model = tf.keras.Model(inputs = [rgb, lab], outputs = final)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.keras.utils.to_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'keras.preprocessing.image.DirectoryIterator'>\"}), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit([train_datagen, gray_train_datagen], epochs\u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m [test_datagen, gray_test_datagen], verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.0\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.0\\Lib\\site-packages\\keras\\engine\\data_adapter.py:1082\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1079\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m   1080\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m   1081\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m-> 1082\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1083\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1084\u001b[0m             _type_name(x), _type_name(y)\n\u001b[0;32m   1085\u001b[0m         )\n\u001b[0;32m   1086\u001b[0m     )\n\u001b[0;32m   1087\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1089\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[0;32m   1092\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'keras.preprocessing.image.DirectoryIterator'>\"}), <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "model.fit([train_datagen, gray_train_datagen], epochs= 30, validation_data= [test_datagen, gray_test_datagen], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
